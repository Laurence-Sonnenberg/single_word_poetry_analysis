---
title: "Analyzing Sentiment in Early 19th Century Poetry Using tidytext"
author: "Laurence Sonnenberg"
output: 
  html_document:
    theme: lumen
    highlight: haddock
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


When reading poetry, it feels as if you are reading emotion. A good poet can use words to bring to their reader whichever emotions they choose. To do this, these poets often have to look deep within themselves, using their own lives as fuel. For this reason you would expect that poets and as a result, their poetry, would be influenced by the events happening around them. If certain events caused the poet's view of the world to be an unhappy one, you'd expect their poetry to be unhappy, and of course the same for the opposite. 

In this analysis I attempt to show this relation between world events and the poets of those times.  

Gathering the required data -- this being poems and their dates -- proved to be a very difficult task. I had initially hoped to be able to show an analysis of the entire 20th century (this may still happen when I find more time and/or sources), but in the end I settled for the years between 1890 - 1925. I managed to collect an overall number of 97 poems (a few of which are excluded from the analysis due to being written in 1888 or 1889) from 6 of the most well known poets of the time. These poets being:

- William Yeats
- T. S. Eliot
- Robert Frost
- Wallace Stevens
- E. E. Cummings
- D. H. Lawrence

I will only be going through the preparation code for Yeats. The rest is similar but not exactly the same, and can be found in my github repository if anyone would like to re-create anything I have done. The actual analysis is done using all poets/poems combined. 

Firstly I load the packages I'm going to need.

```{r load_packages, message = FALSE}

library(tidyverse)
library(tidytext)
library(stringr)
library(rvest)
library(lubridate)

```

```{r all_functions, message = FALSE, include = FALSE}

## Scrape Yeats ##

Yeats <- function() {
  
  # function to scrape for poem and it's date using poem names 
  
  GetPoemAndDate <- function(poemName) {
    
    nameVec <- unlist(str_split(poemName, pattern = " "))
    
    url <- str_c("http://www.poetry-archive.com/y/", 
                 paste(nameVec, collapse = "_"),
                 ".html") 
    
    poem <- url %>%
      read_html() %>%
      html_nodes("dl") %>%
      html_text() %>%
      str_replace_all(pattern = "\r", replacement = "") %>%
      str_replace_all(pattern = "\n", replacement = " ") %>%
      str_replace_all(pattern = "[  ]{2}", replacement = "")
    
    date <- url %>%
      read_html() %>%
      html_nodes("td font") %>%
      html_text() 
    
    date <- date[3] %>%
      str_extract(pattern = "[0-9]+")
   
    # pause before function return
    
    Sys.sleep(runif(1,0,1))
    
    return(list(poem = poem, date = date))
  }
  
  # function to analyse poems and return scores
  
  bingAnalysePoems <- function(i) {
    
    poem <- data_frame(poem = poemDataFrame$poem[i])
    
    textTokenized <- poem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    bing <- sentiments %>%
      filter(lexicon == "bing") %>%
      select(-score)
    
    poemSentiment <- tidyPoem %>%
      inner_join(bing) 
    
    poemSentiment <- poemSentiment %>%
      mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
    
    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
    
    return(finalScore)
  }
  
  # nrs analysis function 
  
  nrcAnalysePoems <- function(sent) {
    
    textTokenized <- nrsPoem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    nrcSentiment <- sentiments %>%
      filter(lexicon == "nrc", sentiment == sent)
    
    sentimentInPoem <- tidyPoem %>%
      semi_join(nrcSentiment) %>%
      count(word, sort = TRUE)
    
    return(sum(sentimentInPoem$n))
  }
  
  # page url
  
  poemNameUrl <- "http://www.poetry-archive.com/y/yeats_w_b.html"
  
  # scrape for poem names
  
  poemName <- poemNameUrl %>%
    read_html() %>%
    html_nodes("a font") %>%
    html_text() 
  
  poemName <- poemName[1:50] %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
    str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
    tolower()
  
  # hardcode 2 poem names to fit in with used url name
  
  poemName[9] <- "he mourns for the change"
  poemName[24] <- "the old men admiring themselves"
  
  # get poems and dates
  
  poemDataFrame <- list()
  count <- 1
  
  for (name in poemName) {
    
    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, 
                                      date = GetPoemAndDate(name)$date,
                                      stringsAsFactors = FALSE)
    
    count <- count + 1
  }
  
  # rbind all poems and dates
  
  poemDataFrame <- do.call(rbind, poemDataFrame)
  
  # create data frame of names, poems and dates
  
  poemDataFrame <- cbind(poemName, poemDataFrame)
  
  # hardcode single date with error
  
  poemDataFrame$date[40] <- "1916"
  
  # get scores
  
  scores <- sapply(1:length(poemDataFrame$poem), bingAnalysePoems)
  
  # create data frame with data and scores
  
  dateAndScore <- data.frame(scores) %>%
    mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01")))) 
  
  # do nrs analysis
  
  sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                     "joy","sadness", "surprise", "trust")
  
  nrsAnalysisDataFrame <- list()
  
  for (i in 1:length(poemDataFrame$poem)) {
    
    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])

    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
      rownames_to_column() %>%
      select(sentiment = rowname, value = 2) %>%
      mutate(name = poemDataFrame$poemName[i], 
             date = poemDataFrame$date[i])
    
    nrsAnalysisDataFrame[[i]] <- nrsDataFrame
  }
  
  # rbind all nrs analysis
  
  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)
  
  # return data frames 
  
  return(list(dateAndScore, nrsAnalysisDataFrame))
}


## Scrape Eliot ##

Eliot <- function() {
  
  # function to scrape for poem and it's date using poem names
  
  GetPoemAndDate <- function(poemName) {
    
    nameVec <- unlist(str_split(poemName, pattern = " "))
    
    url <- str_c("http://www.poetry-archive.com/e/", 
                 paste(nameVec, collapse = "_"),
                 ".html") 
    
    poem <- url %>%
      read_html() %>%
      html_nodes("dl") %>%
      html_text() %>%
      str_replace_all(pattern = "\r", replacement = "") %>%
      str_replace_all(pattern = "\n", replacement = " ") %>%
      str_replace_all(pattern = "[  ]{2}", replacement = "")
    
    date <- url %>%
      read_html() %>%
      html_nodes("td font") %>%
      html_text() 
    
    date <- date[4] %>%
      str_extract(pattern = "[0-9]+")
    
    # pause before function return
    
    Sys.sleep(runif(1,0,1))
    
    return(list(poem = poem, date = date))
  }
  
  # function to analyse poems and return scores
  
  AnalysePoems <- function(i) {
    
    poem <- data_frame(poem = poemDataFrame$poem[i])
    
    textTokenized <- poem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    bing <- sentiments %>%
      filter(lexicon == "bing") %>%
      select(-score)
    
    poemSentiment <- tidyPoem %>%
      inner_join(bing) 
    
    poemSentiment <- poemSentiment %>%
      mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
    
    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
    
    return(finalScore)
  }
  
  # nrs analysis function 
  
  nrcAnalysePoems <- function(sent) {
    
    textTokenized <- nrsPoem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    nrcSentiment <- sentiments %>%
      filter(lexicon == "nrc", sentiment == sent)
    
    sentimentInPoem <- tidyPoem %>%
      semi_join(nrcSentiment) %>%
      count(word, sort = TRUE)
    
    return(sum(sentimentInPoem$n))
  }
  
  # page url
  
  poemNameUrl <- "http://www.poetry-archive.com/e/eliot_t_s.html"
  
  # scrape for poem names
  
  poemName <- poemNameUrl %>%
    read_html() %>%
    html_nodes("a font") %>%
    html_text() 
  
  poemName <- poemName[1:(length(poemName) - 2)] %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
    str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
    tolower()
  
  # hardcode 2 poem names to fit in with used url name
  
  poemName[3] <- "love song of j alfred prufrock"
  
  # get poems and dates
  
  poemDataFrame <- list()
  count <- 1
  
  for (name in poemName) {
    
    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, 
                                         date = GetPoemAndDate(name)$date,
                                         stringsAsFactors = FALSE)
    
    count <- count + 1
  }
  
  # rbind all poems and dates
  
  poemDataFrame <- do.call(rbind, poemDataFrame)
  
  # create data frame of names, poems and dates
  
  poemDataFrame <- cbind(poemName, poemDataFrame)
  
  # get scores
  
  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)
  
  dateAndScore <- data.frame(scores) %>%
    mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01")))) 

  # do nrs analysis
  
  sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                     "joy","sadness", "surprise", "trust")
  
  nrsAnalysisDataFrame <- list()
  
  for (i in 1:length(poemDataFrame$poem)) {
    
    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])
    
    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
      rownames_to_column() %>%
      select(sentiment = rowname, value = 2) %>%
      mutate(name = poemDataFrame$poemName[i], 
             date = poemDataFrame$date[i])
    
    nrsAnalysisDataFrame[[i]] <- nrsDataFrame
  }
  
  # rbind all nrs analysis
  
  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)
  
  # return data frames 
  
  return(list(dateAndScore, nrsAnalysisDataFrame))
}

## Scrape for Frost ##

Frost <- function() {
  
  # function to scrape for poem and it's date using poem names
  
  GetPoemAndDate <- function(poemName) {
    
    nameVec <- unlist(str_split(poemName, pattern = " "))
    
    url <- str_c("http://www.poetry-archive.com/f/", 
                 paste(nameVec, collapse = "_"),
                 ".html") 
    
    poem <- url %>%
      read_html() %>%
      html_nodes("dl") %>%
      html_text() %>%
      str_replace_all(pattern = "\r", replacement = "") %>%
      str_replace_all(pattern = "\n", replacement = " ") %>%
      str_replace_all(pattern = "[  ]{2}", replacement = "")
    
    date <- url %>%
      read_html() %>%
      html_nodes("td font") %>%
      html_text() 
    
    date <- date[4] %>%
      str_extract(pattern = "[0-9]+")
    
    # pause before function return
    
    Sys.sleep(runif(1,0,1))
    
    return(list(poem = poem, date = date))
  }
  
  # function to analyse poems and return scores
  
  AnalysePoems <- function(i) {
    
    poem <- data_frame(poem = poemDataFrame$poem[i])
    
    textTokenized <- poem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    bing <- sentiments %>%
      filter(lexicon == "bing") %>%
      select(-score)
    
    poemSentiment <- tidyPoem %>%
      inner_join(bing) 
    
    poemSentiment <- poemSentiment %>%
      mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
    
    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
    
    return(finalScore)
  }
  
  # nrs analysis function 
  
  nrcAnalysePoems <- function(sent) {
    
    textTokenized <- nrsPoem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    nrcSentiment <- sentiments %>%
      filter(lexicon == "nrc", sentiment == sent)
    
    sentimentInPoem <- tidyPoem %>%
      semi_join(nrcSentiment) %>%
      count(word, sort = TRUE)
    
    return(sum(sentimentInPoem$n))
  }
  
  # page url
  
  poemNameUrl <- "http://www.poetry-archive.com/f/frost_robert.html"
  
  # scrape for poem names
  
  poemName <- poemNameUrl %>%
    read_html() %>%
    html_nodes("a font") %>%
    html_text() 
  
  poemName <- poemName[1:(length(poemName) - 2)] %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
    str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
    tolower()
  
  # hardcode poem name to fit in with used url name
  
  poemName[10] <- "the_oft-repeated_dream"
  poemName[14] <- "range_finding"
  poemName[20] <- "the_wood-pile"
  
  # get poems and dates
  
  poemDataFrame <- list()
  count <- 1
  
  for (name in poemName) {
    
    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, 
                                         date = GetPoemAndDate(name)$date,
                                         stringsAsFactors = FALSE)
    
    count <- count + 1
  }
  
  # rbind all poems and dates
  
  poemDataFrame <- do.call(rbind, poemDataFrame)
  
  # create data frame of names, poems and dates
  
  poemDataFrame <- cbind(poemName, poemDataFrame)
  
  # get scores
  
  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)
  
  dateAndScore <- data.frame(scores) %>%
    mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01")))) 

  # do nrs analysis
  
  sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                     "joy","sadness", "surprise", "trust")
  
  nrsAnalysisDataFrame <- list()
  
  for (i in 1:length(poemDataFrame$poem)) {
    
    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])
    
    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
      rownames_to_column() %>%
      select(sentiment = rowname, value = 2) %>%
      mutate(name = poemDataFrame$poemName[i], 
             date = poemDataFrame$date[i])
    
    nrsAnalysisDataFrame[[i]] <- nrsDataFrame
  }
  
  # rbind all nrs analysis
  
  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)
  
  # return data frames 
  
  return(list(dateAndScore, nrsAnalysisDataFrame))
}

## Scrape for Wallace ##

Wallace <- function() {
  
  # function to scrape for poem and it's date using poem names
  
  GetPoemAndDate <- function(poemName) {
    
    nameVec <- unlist(str_split(poemName, pattern = " "))
    
    url <- str_c("http://www.poetry-archive.com/s/", 
                 paste(nameVec, collapse = "_"),
                 ".html") 
    
    poem <- url %>%
      read_html() %>%
      html_nodes("dl") %>%
      html_text() %>%
      str_replace_all(pattern = "\r", replacement = "") %>%
      str_replace_all(pattern = "\n", replacement = " ") %>%
      str_replace_all(pattern = "[  ]{2}", replacement = "")
    
    date <- url %>%
      read_html() %>%
      html_nodes("td font") %>%
      html_text() 
    
    date <- date[3] %>%
      str_extract(pattern = "[0-9]+")
    
    # pause before function return
    
    Sys.sleep(runif(1,0,1))
    
    return(list(poem = poem, date = date))
  }
  
  # function to analyse poems and return scores
  
  AnalysePoems <- function(i) {
    
    poem <- data_frame(poem = poemDataFrame$poem[i])
    
    textTokenized <- poem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    bing <- sentiments %>%
      filter(lexicon == "bing") %>%
      select(-score)
    
    poemSentiment <- tidyPoem %>%
      inner_join(bing) 
    
    poemSentiment <- poemSentiment %>%
      mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
    
    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
    
    return(finalScore)
  }
  
  # nrs analysis function 
  
  nrcAnalysePoems <- function(sent) {
    
    textTokenized <- nrsPoem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    nrcSentiment <- sentiments %>%
      filter(lexicon == "nrc", sentiment == sent)
    
    sentimentInPoem <- tidyPoem %>%
      semi_join(nrcSentiment) %>%
      count(word, sort = TRUE)
    
    return(sum(sentimentInPoem$n))
  }
  
  # page url
  
  poemNameUrl <- "http://www.poetry-archive.com/s/stevens_wallace.html"
  
  # scrape for poem names
  
  poemName <- poemNameUrl %>%
    read_html() %>%
    html_nodes("a font") %>%
    html_text() 
  
  poemName <- poemName[1:(length(poemName) - 2)] %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
    str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
    tolower()
  
  # hardcode poem name to fit in with used url name
  
  poemName[1] <- "the_emperor_of_ice_cream"
  poemName[2] <- "a_high_toned_old_christian_woman"
  # poemName[20] <- "the_wood-pile"
  
  # get poems and dates
  
  poemDataFrame <- list()
  count <- 1
  
  for (name in poemName) {
    
    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, 
                                         date = GetPoemAndDate(name)$date,
                                         stringsAsFactors = FALSE)
    
    count <- count + 1
  }
  
  # rbind all poems and dates
  
  poemDataFrame <- do.call(rbind, poemDataFrame)
  
  poemDataFrame$date[3] <- "1921"
  
  # create data frame of names, poems and dates
  
  poemDataFrame <- cbind(poemName, poemDataFrame)
  
  # get scores
  
  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)
  
  dateAndScore <- data.frame(scores) %>%
    mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01"))))
  
  # do nrs analysis
  
  sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                     "joy","sadness", "surprise", "trust")
  
  nrsAnalysisDataFrame <- list()
  
  for (i in 1:length(poemDataFrame$poem)) {
    
    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])
    
    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
      rownames_to_column() %>%
      select(sentiment = rowname, value = 2) %>%
      mutate(name = poemDataFrame$poemName[i], 
             date = poemDataFrame$date[i])
    
    nrsAnalysisDataFrame[[i]] <- nrsDataFrame
  }
  
  # rbind all nrs analysis
  
  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)
  
  # return data frames 
  
  return(list(dateAndScore, nrsAnalysisDataFrame))
}

## Scrape for Cummings ##

Cummings <- function() {
  
  # function to scrape for poem and it's date using poem names
  
  GetPoemAndDate <- function(poemName) {
    
    nameVec <- unlist(str_split(poemName, pattern = " "))
    
    url <- str_c("http://www.poetry-archive.com/c/", 
                 paste(nameVec, collapse = "_"),
                 ".html") 
    
    poem <- url %>%
      read_html() %>%
      html_nodes("dl") %>%
      html_text() %>%
      str_replace_all(pattern = "\r", replacement = "") %>%
      str_replace_all(pattern = "\n", replacement = " ") %>%
      str_replace_all(pattern = "[  ]{2}", replacement = "")
    
    date <- url %>%
      read_html() %>%
      html_nodes("td font") %>%
      html_text() 
    
    date <- date[4] %>%
      str_extract(pattern = "[0-9]{4}")
    
    # pause before function return
    
    Sys.sleep(runif(1,0,1))
    
    return(list(poem = poem, date = date))
  }
  
  # function to analyse poems and return scores
  
  AnalysePoems <- function(i) {
    
    poem <- data_frame(poem = poemDataFrame$poem[i])
    
    textTokenized <- poem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    bing <- sentiments %>%
      filter(lexicon == "bing") %>%
      select(-score)
    
    poemSentiment <- tidyPoem %>%
      inner_join(bing) 
    
    poemSentiment <- poemSentiment %>%
      mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
    
    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
    
    return(finalScore)
  }
  
  # nrs analysis function 
  
  nrcAnalysePoems <- function(sent) {
    
    textTokenized <- nrsPoem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    nrcSentiment <- sentiments %>%
      filter(lexicon == "nrc", sentiment == sent)
    
    sentimentInPoem <- tidyPoem %>%
      semi_join(nrcSentiment) %>%
      count(word, sort = TRUE)
    
    return(sum(sentimentInPoem$n))
  }
  
  # page url
  
  poemNameUrl <- "http://www.poetry-archive.com/c/cummings_e_e.html"
  
  # scrape for poem names
  
  poemName <- poemNameUrl %>%
    read_html() %>%
    html_nodes("a font") %>%
    html_text() 
  
  poemName <- poemName[1:(length(poemName) - 2)] %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
    str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
    tolower()
  
  # get poems and dates
  
  poemDataFrame <- list()
  count <- 1
  
  for (name in poemName) {
    
    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, 
                                         date = GetPoemAndDate(name)$date,
                                         stringsAsFactors = FALSE)
    
    count <- count + 1
  }
  
  # rbind all poems and dates
  
  poemDataFrame <- do.call(rbind, poemDataFrame)
  
  # create data frame of names, poems and dates
  
  poemDataFrame <- cbind(poemName, poemDataFrame)
  
  # get scores
  
  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)
  
  dateAndScore <- data.frame(scores) %>%
    mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01")))) 

  # do nrs analysis
  
  sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                     "joy","sadness", "surprise", "trust")
  
  nrsAnalysisDataFrame <- data.frame()
  
  for (i in 1:length(poemDataFrame$poem)) {
    
    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])

    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
      rownames_to_column() %>%
      select(sentiment = rowname, value = 2) %>%
      mutate(name = poemDataFrame$poemName[i], 
             date = poemDataFrame$date[i])
    
    nrsAnalysisDataFrame <- rbind(nrsAnalysisDataFrame, nrsDataFrame)
  }
  
  # return data frames 
  
  return(list(dateAndScore, nrsAnalysisDataFrame))
}

## Scrape for Lawrence ##

Lawrence <- function() {
  
  # function to scrape for poem and it's date using poem names
  
  GetPoemAndDate <- function(poemName) {
    
    nameVec <- unlist(str_split(poemName, pattern = " "))
    
    url <- str_c("http://www.poetry-archive.com/l/", 
                 paste(nameVec, collapse = "_"),
                 ".html") 
    
    poem <- url %>%
      read_html() %>%
      html_nodes("dl") %>%
      html_text() %>%
      str_replace_all(pattern = "\r", replacement = "") %>%
      str_replace_all(pattern = "\n", replacement = " ") %>%
      str_replace_all(pattern = "[  ]{2}", replacement = "")
    
    date <- url %>%
      read_html() %>%
      html_nodes("td font") %>%
      html_text() 
    
    date <- date[4] %>%
      str_extract(pattern = "[0-9]{4}")
    
    # pause before function return
    
    Sys.sleep(runif(1,0,1))
    
    return(list(poem = poem, date = date))
  }
  
  # function to analyse poems and return scores
  
  AnalysePoems <- function(i) {
    
    poem <- data_frame(poem = poemDataFrame$poem[i])
    
    textTokenized <- poem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    bing <- sentiments %>%
      filter(lexicon == "bing") %>%
      select(-score)
    
    poemSentiment <- tidyPoem %>%
      inner_join(bing) 
    
    poemSentiment <- poemSentiment %>%
      mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
    
    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
    
    return(finalScore)
  }
  
  # nrs analysis function 
  
  nrcAnalysePoems <- function(sent) {
    
    textTokenized <- nrsPoem %>%
      unnest_tokens(word, poem)
    
    data("stop_words")
    
    tidyPoem <- textTokenized %>%
      anti_join(stop_words)
    
    nrcSentiment <- sentiments %>%
      filter(lexicon == "nrc", sentiment == sent)
    
    sentimentInPoem <- tidyPoem %>%
      semi_join(nrcSentiment) %>%
      count(word, sort = TRUE)
    
    return(sum(sentimentInPoem$n))
  }
  
  # page url
  
  poemNameUrl <- "http://www.poetry-archive.com/l/lawrence_d_h.html"
  
  # scrape for poem names
  
  poemName <- poemNameUrl %>%
    read_html() %>%
    html_nodes("a font") %>%
    html_text() 
  
  poemName <- poemName[1:(length(poemName) - 2)] %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
    str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
    tolower()
  
  # get poems and dates
  
  poemDataFrame <- list()
  count <- 1
  
  for (name in poemName) {
    
    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, 
                                         date = GetPoemAndDate(name)$date,
                                         stringsAsFactors = FALSE)
    
    count <- count + 1
  }
  
  # rbind all poems and dates
  
  poemDataFrame <- do.call(rbind, poemDataFrame)
  
  # hardcode single date with error 
  
  poemDataFrame$date[3] <- 1916
  
  # create data frame of names, poems and dates
  
  poemDataFrame <- cbind(poemName, poemDataFrame)
  
  # get scores
  
  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)
  
  dateAndScore <- data.frame(scores) %>%
    mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01")))) 

  # do nrs analysis
  
  sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                     "joy","sadness", "surprise", "trust")
  
  nrsAnalysisDataFrame <- list()
  
  for (i in 1:length(poemDataFrame$poem)) {
    
    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])
    
    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
      rownames_to_column() %>%
      select(sentiment = rowname, value = 2) %>%
      mutate(name = poemDataFrame$poemName[i], 
             date = poemDataFrame$date[i])
    
    nrsAnalysisDataFrame[[i]] <- nrsDataFrame
  }
  
  # rbind all nrs analysis
  
  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)
  
  # return data frames 
  
  return(list(dateAndScore, nrsAnalysisDataFrame))
}

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

The website I use for scraping has a page for each poet which lists the poems available -- then it has a seperate page for each of the poems in the list, along with their dates. I have chosen this website specifically because having each poem dated is a must for my analysis. I run an initial scrape using `rvest` to get the names which are then cleaned so they can be used in the urls to get the poems and dates. Some names are not exactly the same as their url versions, so they need to be manually changed. 

```{r scrape_poem_names}

# page url
poemNameUrl <- "http://www.poetry-archive.com/y/yeats_w_b.html"

# scrape for poem names
poemName <- poemNameUrl %>%
  read_html() %>%
  html_nodes("a font") %>%
  html_text() 

# clean names
poemName <- poemName[1:50] %>%
  str_replace_all(pattern = "\r", replacement = "") %>%
  str_replace_all(pattern = "\n", replacement = " ") %>%
  str_replace_all(pattern = "[  ]{2}", replacement = "") %>%
  str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
  tolower()

# hardcode 2 poem names to fit in with used url name
poemName[9] <- "he mourns for the change"
poemName[24] <- "the old men admiring themselves"

# display
head(poemName, 10)
  
```

Next I need to scrape the website for the poems and their dates. To do this I use a function that takes a poem name -- and again using `rvest` -- scrapes for the given poem and its date, then cleans the text and waits before returning. The wait is so that I don't send too many requests to the website in quick succession. 

```{r get_poem_and_date_function}

# function to scrape for poem and its date using poem names 
GetPoemAndDate <- function(poemName) {
  
  # split string at empty space and unlist the result  
  nameVec <- unlist(str_split(poemName, pattern = " "))
  
  # use result in url 
  url <- str_c("http://www.poetry-archive.com/y/", 
               paste(nameVec, collapse = "_"),
               ".html") 
  
  # scrape for poem and clean
  poem <- url %>%
    read_html() %>%
    html_nodes("dl") %>%
    html_text() %>%
    str_replace_all(pattern = "\r", replacement = "") %>%
    str_replace_all(pattern = "\n", replacement = " ") %>%
    str_replace_all(pattern = "[  ]{2}", replacement = "")
  
  # scrape for date 
  date <- url %>%
    read_html() %>%
    html_nodes("td font") %>%
    html_text() 
  
  # clean dates
  date <- date[3] %>%
    str_extract(pattern = "[0-9]+")
 
  # pause before function return
  Sys.sleep(runif(1,0,1))
  
  return(list(poem = poem, date = date))
}

```

I then use the previous function in a for loop which loops through each poems name and scrapes for that particular poem and its date. With each loop I also add the data frame of poem and date to a list. Once the for loop has completed I `rbind` all the data frames together. A complete data frame of all poems and dates will be needed for the next step.

```{r get_poem_and_date}

# get poems and dates
poemDataFrame <- list()
count <- 1

for (name in poemName) {
  
  # get poem and date for given poem name
  poemNameDate <- GetPoemAndDate(name)
  
  # create data frame of name and date and add it to list
  poemDataFrame[[count]] <- data.frame(poem = poemNameDate$poem, 
                                       date = poemNameDate$date,
                           stringsAsFactors = FALSE)
  
  count <- count + 1
}

# rbind all poems and dates
poemDataFrame <- do.call(rbind, poemDataFrame)

```

I then combine the names from the original scrape, the dates, and the poems into a single data frame so they will be ready for me to work with. I also take a look at all the text, checking for and correcting any errors that could negatively affect my analysis. In this case I have found an error in a date.

```{r combine_names_dates_poems}

# create data frame of names, poems and dates
poemDataFrame <- cbind(poemName, poemDataFrame)

# hardcode single date with error
poemDataFrame$date[40] <- "1916"

```

The next function I have written takes a row index, and using the combined data frame of poems, names and dates, along with `tidytext`, tokenizes the poem found at that index into single words. It then uses `anti_join` from `dplyr`, along with the `stop_words` dataset from `tidytext`, to create a tibble  -- this tibble will now be missing a list of stop words which will not be helpful in the analysis. This list of words for each poem is then used to create a sentiment score. This is done using `inner_join` and the `sentiment` dataset filtered on the bing lexicon, again from `tidytext`. The function calculates the sentiment score value for the poem depending on the number of negative and positive words in the list -- negative words get a value of -1 and positive get a value of 1, these values are then summed and the result returned as a percentage of the number of words in that particular poem.  

```{r bing_analysis_function}

# function to analyse poems and return scores using bing lexicon
bingAnalysePoems <- function(i) {
  
  # get poem a index i
  poem <- data_frame(poem = poemDataFrame$poem[i])
  
  # tokenize into words
  textTokenized <- poem %>%
    unnest_tokens(word, poem)
  
  # load stop words dataset
  data("stop_words")
  
  # anti join on stop words
  tidyPoem <- textTokenized %>%
    anti_join(stop_words)
  
  # filter on bing lexicon
  bing <- sentiments %>%
    filter(lexicon == "bing") %>%
    select(-score)
  
  # join on bing to get whether words are positive or negative
  poemSentiment <- tidyPoem %>%
    inner_join(bing) 
  
  # get score for poem
  poemSentiment <- poemSentiment %>%
    mutate(score = ifelse(poemSentiment$sentiment == "positive", 1, -1))
  
  # get score as a percentage of total words in poem
  finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10
  
  return(finalScore)
}

```

Now, using the previous function and `sapply` I get the score for each poem and create a data frame with the poems score and its date. These scores will be used later to show the change in sentiment per year.

```{r get_scores, message = FALSE}

# get scores
scores <- sapply(1:length(poemDataFrame$poem), bingAnalysePoems)

# create data frame with data and scores
dateAndScore <- data.frame(scores) %>%
  mutate(date = year(ymd(str_c(poemDataFrame$date, "/01/01"))))
  
# display
head(dateAndScore, 10)

```

The next function I have written takes a particular sentiment, which in this case can also be called an emotion, from a number of sentiments found in the NRC lexicon of the `sentiment` dataset; it then again creates a tibble of words not including the stop words, and using `semi_join` and the `sentiment` dataset filtered on the NRC lexicon and the particular sentiment given, returns the sum of the number of words relating to that sentiment. These sums will be used to show which emotions were high (or low) in a particular year.

```{r nrc_analysis_function}

# NRC analysis function
nrcAnalysePoems <- function(sent) {
  
  # nrcPoem used from global environment
  textTokenized <- nrcPoem %>%
    unnest_tokens(word, poem)
  
  # load stop words dataset
  data("stop_words")
  
  tidyPoem <- textTokenized %>%
    anti_join(stop_words)
  
  # filter on NRC lexicon and sentiment
  nrcSentiment <- sentiments %>%
    filter(lexicon == "nrc", sentiment == sent)
  
  # join on sentiment and count words
  sentimentInPoem <- tidyPoem %>%
    semi_join(nrcSentiment) %>%
    count(word, sort = TRUE)
  
  # return the sum of the counted words
  return(sum(sentimentInPoem$n))
}

```

Using the above function and `sapply`, I get the sums for each different sentiment in my sentiments list; this is done within a for loop, which loops through each poem, creating a data frame with each row consisting of a sentiment, the sum of words for that sentiment, the name of the poem the sentiment relates to, and the poems date. I then add this data frame to a list which will be used in my next step.

```{r nrc_analysis, message = FALSE}

# list of used setiments found in NRC lexicon
sentimentsVec <- c("anger", "anticipation", "disgust", "fear",
                   "joy","sadness", "surprise", "trust")

# create empty list 
nrcAnalysisDataFrame <- list()

# get a frequency percetage for each sentiment found in the NRC lexicon 
for (i in 1:length(poemDataFrame$poem)) {
  
  # poem at index i - to be used in nrcAnalysePoems function environment
  nrcPoem <- data_frame(poem = poemDataFrame$poem[i])
  
  # create data frame for each poem of all sentiment sums
  nrcDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%
    rownames_to_column() %>%
    select(sentiment = rowname, value = 2) %>%
         mutate(name = poemDataFrame$poemName[i], 
                date = poemDataFrame$date[i])
  
  # add data frame to list
  nrcAnalysisDataFrame[[i]] <- nrcDataFrame
}

```

Once the for loop has completed I `rbind` all the data frames in the list so that I can work with all of them together as a whole.

```{r rbind_NRC}


# rbind list of all NRC sum values for all poems
nrcAnalysisDataFrame <- do.call(rbind, nrcAnalysisDataFrame)

# display
head(nrcAnalysisDataFrame, 10)

```

Now all the preparation code is done and we are ready to begin analyzing. For ease of use I have created a function for each poet to run all the code shown previously; the functions return both the bing and the NRC data frames, ready to be used. These functions are run but will not be shown here. 

Firstly I will need to call each poet's function and assign the returned data frames to variables so that I can work with them as needed. 

```{r call_poet_functions, message = FALSE}

yeats <- Yeats()
eliot <- Eliot()
frost <- Frost()
wallace <- Wallace()
cummings <- Cummings()
lawrence <- Lawrence()

```

Next I will join all the bing scores for all poems using `rbind`, I do this so that I can work with all the data at once. I then group by date and get a mean score for each year in the complete data frame. This returns a tibble of scores and dates which I can now plot.

```{r join_bing}

# rbind data frames and summarize
completedataFramebing <- rbind(yeats[[1]],
                               eliot[[1]],
                               frost[[1]],
                             wallace[[1]],
                            cummings[[1]],
                            lawrence[[1]]) %>%
  filter(!(date %in% c("1888", "1889"))) %>%
  group_by(date)  %>%
  summarize(score = mean(scores))

# display
head(completedataFramebing, 10)

```

I use multiplot so that I can show two different plots side by side. 

```{r plot_bing, fig.height = 4, fig.width = 8}

# plot bar plot
p1 <- ggplot(data = completedataFramebing) +
  geom_bar(aes(x = date, y = score, fill = score), 
           stat = "identity", position = "identity") +
  ylim(-1, 1) +
  ylab("mean percentage score") +
  xlab("year") +
  theme(legend.key.size = unit(0.5, "cm"),
        legend.text = element_text(size = 7),
        legend.position = c(0.87, 0.77)) + 
  ggtitle("Bar Plot of Percentage Scores") +
  theme(plot.title = element_text(size = 12))

# plot dot and line plot
p2 <- ggplot(data = completedataFramebing) +
  geom_line(aes(x = date, y = score), colour = "blue") +
  geom_point(aes(x = date, y = score), size = 1.3, colour = "blue") +
  ylim(-1, 1) +
  ylab("mean percentage score") +
  xlab("year") +
  ggtitle("Dot and Line Plot of Percentage Scores") +
  theme(plot.title = element_text(size = 12))

# use multiplot function 
# can be found at http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
multiplot(p1, p2, cols = 2)

```

The 0 values in the bar plot are not all actual 0 values but rather years where no information is available. When looking at the plots we can see a steady decline between the period 1890 - 1900, then due to a lack of data very little can be seen during the period from 1900 - 1915, after which there is again a massive decline between 1915 and 1920 and again a small drop between 1920 and 1925.

Finally, let's do the NRC analysis. Firstly, I join together all the poet's NRC data frames using `rbind`, again so I can work with all the data at once. I then group them by date and sentiment, sum the sentiment values for each poem and use this sum to get percentage values for each sentiment in each year. Once I have done this the data frame is ready to be plotted.

```{r join_NRC}

# rbind data frames and summarize
yeatsnrc <- rbind(yeats[[2]],
                  eliot[[2]],
                  frost[[2]],
                wallace[[2]],
               cummings[[2]],
               lawrence[[2]]) %>%
  filter(!(date %in% c("1888", "1889"))) %>%
  group_by(date, sentiment) %>%
  summarise(dateSum = sum(value)) %>%
  mutate(dateFreqPerc = dateSum/sum(dateSum))


head(yeatsnrc, 10)

```

I use `facet_wrap` on the date so that I can display all the plots for all the years at once.

```{r plot_NRC, fig.height = 8, fig.width = 6}

# plot multiple NRC barplots using facet wrap
ggplot(data = yeatsnrc, aes(x = sentiment, 
                            y = dateFreqPerc, 
                         fill = sentiment)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Spectral") +
  guides(fill = FALSE) +
  facet_wrap(~date, ncol = 2) +
  theme(axis.text.x = element_text(
              angle = 45, 
              hjust = 1,
               size = 8)) +
 theme(axis.title.y = element_text(margin = margin(0, 10, 0, 0))) +
  ylab("frequency percentage") +
  ggtitle("Bar Plots for Sentiment Percentages Per Year") +
  theme(plot.title = element_text(size = 14))

```

Looking at these plots we can see how sentiment changes through the years of available data. During the early 1890s we see equal percentages of anticipation, fear, joy, sadness and trust, while later we see anticipation, joy and trust. In 1903 joy takes the lead, but in 1910 and 1915 we see anticipation and trust increasing with fear and joy equal. In 1916 fear and sadness are high and 1917 anger, fear, sadness and trust are notibly high. From 1918 - 1919 we see a change from negative to positive with joy taking a big lead in 1919 and again in 1920. 1921 sees sadness again with others coming in with mostly equal percentages, and 1922 anticipation, joy and trust. 

I am not a historian but fortunately my sister majored in history, so I asked her to send me a timeline of influencial world events between the years this analysis is based on. I have used this timeline to explain my findings. 

From both the bing and NRC analysis it can be seen that there was a very apparent negative trend during the years from 1915 - 1920, this is very possibly due to a number of world events, namely; World War I during the years from 1914 - 1918, the influenza pandemic which lasted from 1918 - 1919, and the Russian Revolution in 1917. Another negative trend seems to appear at the end of the 19th Century, this time it is possibly due to the Boer War, which lasted from 1899 - 1902 and had repurcussions across Europe, as well as the India epidemic which killed around 1 million people during the years 1899 and 1900. 

A few things to be mentioned:  

<ol>
<li> A word from a colleague who majored in english literature; as we all know the pop artists of the time will always move with popular trends, so it could be that the poets chosen, being the most popular during the years this analysis is based on, may have been more likely to be influenced by the events around them </li>
<li> Due to the surprisingly difficult task of finding poetry with enough information, this analysis has been based on only a small number of poems </li>
</ol>


This being said, it still seems very likely that there is a relation between poets and the world events of their time. 



