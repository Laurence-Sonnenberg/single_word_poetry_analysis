{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Sentiment Analysis in Poetry from 1890 - 1925\"\nauthor: \"Laurence Sonnenberg\"\noutput: \n  html_document:\n    theme: lumen\n    highlight: haddock\n---\n\n```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n\nWhen reading poetry, it feels as if you are reading emotion. A good poet can use words to bring to their reader whichever emotions they choose. To do this, these poets often have to look deep within themselves, using their own lives as fuel. For this reason you would expect that poets and as a result, their poetry, would be influenced by the events happening around them. If certain events caused the poet's view of the world to be an unhappy one, you'd expect their poetry to be unhappy, and of course the same for the opposite. \n\nIn this analysis I attempt to show this relation between world events and the poets of those times.  \n\nGathering the required data -- this being poems and their dates -- proved to be a very difficult task. I had initially hoped to be able to show an analysis of the entire 20th century (this may still happen when I find more time and/or sources), but in the end I settled for the years between 1890 - 1925. I managed to collect an overall number of 97 poems (a few of which are excluded from the analysis due to being written in 1889) from 6 of the most well known poets of the time. These poets being:\n\n- Willaim Yeats\n- T. S. Eliot\n- Robert Frost\n- Wallace Stevens\n- E. E. Cummings\n- D. H. Lawrence\n\nI will be going through the poetry aquisition code for Yeats. The rest is similar but not exactly the same, and can be found in my github repository if anyone would like to re-create anything I have done. The actual analysis is done with all poets/poems combined. \n\nFirstly I load the packages I'm going to need.\n\n```{r load_packages, message = FALSE}\n\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(lubridate)\n\n```\n\n```{r all_functions, message = FALSE, include = FALSE}\n\n## Scrape Yeats ##\n\nYeats <- function() {\n  \n  # function to scrape for poem and it's date using poem names \n  \n  GetPoemAndDate <- function(poemName) {\n    \n    nameVec <- unlist(str_split(poemName, pattern = \" \"))\n    \n    url <- str_c(\"http://www.poetry-archive.com/y/\", \n                 paste(nameVec, collapse = \"_\"),\n                 \".html\") \n    \n    poem <- url %>%\n      read_html() %>%\n      html_nodes(\"dl\") %>%\n      html_text() %>%\n      str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n      str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n      str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n    \n    date <- url %>%\n      read_html() %>%\n      html_nodes(\"td font\") %>%\n      html_text() \n    \n    date <- date[3] %>%\n      str_extract(pattern = \"[0-9]+\")\n   \n    # pause before function return\n    \n    Sys.sleep(runif(1,0,1))\n    \n    return(list(poem = poem, date = date))\n  }\n  \n  # function to analyse poems and return scores\n  \n  bingAnalysePoems <- function(i) {\n    \n    poem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    textTokenized <- poem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    bing <- sentiments %>%\n      filter(lexicon == \"bing\") %>%\n      select(-score)\n    \n    poemSentiment <- tidyPoem %>%\n      inner_join(bing) \n    \n    poemSentiment <- poemSentiment %>%\n      mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n    \n    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n    \n    return(finalScore)\n  }\n  \n  # nrs analysis function \n  \n  nrcAnalysePoems <- function(sent) {\n    \n    textTokenized <- nrsPoem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    nrcSentiment <- sentiments %>%\n      filter(lexicon == \"nrc\", sentiment == sent)\n    \n    sentimentInPoem <- tidyPoem %>%\n      semi_join(nrcSentiment) %>%\n      count(word, sort = TRUE)\n    \n    return(sum(sentimentInPoem$n))\n  }\n  \n  # page url\n  \n  poemNameUrl <- \"http://www.poetry-archive.com/y/yeats_w_b.html\"\n  \n  # scrape for poem names\n  \n  poemName <- poemNameUrl %>%\n    read_html() %>%\n    html_nodes(\"a font\") %>%\n    html_text() \n  \n  poemName <- poemName[1:50] %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n    str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n    tolower()\n  \n  # hardcode 2 poem names to fit in with used url name\n  \n  poemName[9] <- \"he mourns for the change\"\n  poemName[24] <- \"the old men admiring themselves\"\n  \n  # get poems and dates\n  \n  poemDataFrame <- list()\n  count <- 1\n  \n  for (name in poemName) {\n    \n    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, \n                                      date = GetPoemAndDate(name)$date,\n                                      stringsAsFactors = FALSE)\n    \n    count <- count + 1\n  }\n  \n  # rbind all poems and dates\n  \n  poemDataFrame <- do.call(rbind, poemDataFrame)\n  \n  # create data frame of names, poems and dates\n  \n  poemDataFrame <- cbind(poemName, poemDataFrame)\n  \n  # hardcode single date with error\n  \n  poemDataFrame$date[40] <- \"1916\"\n  \n  # get scores\n  \n  scores <- sapply(1:length(poemDataFrame$poem), bingAnalysePoems)\n  \n  # create data frame with data and scores\n  \n  dateAndScore <- data.frame(scores) %>%\n    mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\")))) \n  \n  # do nrs analysis\n  \n  sentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                     \"joy\",\"sadness\", \"surprise\", \"trust\")\n  \n  nrsAnalysisDataFrame <- list()\n  \n  for (i in 1:length(poemDataFrame$poem)) {\n    \n    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])\n\n    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n      rownames_to_column() %>%\n      select(sentiment = rowname, value = 2) %>%\n      mutate(name = poemDataFrame$poemName[i], \n             date = poemDataFrame$date[i])\n    \n    nrsAnalysisDataFrame[[i]] <- nrsDataFrame\n  }\n  \n  # rbind all nrs analysis\n  \n  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)\n  \n  # return data frames \n  \n  return(list(dateAndScore, nrsAnalysisDataFrame))\n}\n\n\n## Scrape Eliot ##\n\nEliot <- function() {\n  \n  # function to scrape for poem and it's date using poem names\n  \n  GetPoemAndDate <- function(poemName) {\n    \n    nameVec <- unlist(str_split(poemName, pattern = \" \"))\n    \n    url <- str_c(\"http://www.poetry-archive.com/e/\", \n                 paste(nameVec, collapse = \"_\"),\n                 \".html\") \n    \n    poem <- url %>%\n      read_html() %>%\n      html_nodes(\"dl\") %>%\n      html_text() %>%\n      str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n      str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n      str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n    \n    date <- url %>%\n      read_html() %>%\n      html_nodes(\"td font\") %>%\n      html_text() \n    \n    date <- date[4] %>%\n      str_extract(pattern = \"[0-9]+\")\n    \n    # pause before function return\n    \n    Sys.sleep(runif(1,0,1))\n    \n    return(list(poem = poem, date = date))\n  }\n  \n  # function to analyse poems and return scores\n  \n  AnalysePoems <- function(i) {\n    \n    poem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    textTokenized <- poem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    bing <- sentiments %>%\n      filter(lexicon == \"bing\") %>%\n      select(-score)\n    \n    poemSentiment <- tidyPoem %>%\n      inner_join(bing) \n    \n    poemSentiment <- poemSentiment %>%\n      mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n    \n    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n    \n    return(finalScore)\n  }\n  \n  # nrs analysis function \n  \n  nrcAnalysePoems <- function(sent) {\n    \n    textTokenized <- nrsPoem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    nrcSentiment <- sentiments %>%\n      filter(lexicon == \"nrc\", sentiment == sent)\n    \n    sentimentInPoem <- tidyPoem %>%\n      semi_join(nrcSentiment) %>%\n      count(word, sort = TRUE)\n    \n    return(sum(sentimentInPoem$n))\n  }\n  \n  # page url\n  \n  poemNameUrl <- \"http://www.poetry-archive.com/e/eliot_t_s.html\"\n  \n  # scrape for poem names\n  \n  poemName <- poemNameUrl %>%\n    read_html() %>%\n    html_nodes(\"a font\") %>%\n    html_text() \n  \n  poemName <- poemName[1:(length(poemName) - 2)] %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n    str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n    tolower()\n  \n  # hardcode 2 poem names to fit in with used url name\n  \n  poemName[3] <- \"love song of j alfred prufrock\"\n  \n  # get poems and dates\n  \n  poemDataFrame <- list()\n  count <- 1\n  \n  for (name in poemName) {\n    \n    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, \n                                         date = GetPoemAndDate(name)$date,\n                                         stringsAsFactors = FALSE)\n    \n    count <- count + 1\n  }\n  \n  # rbind all poems and dates\n  \n  poemDataFrame <- do.call(rbind, poemDataFrame)\n  \n  # create data frame of names, poems and dates\n  \n  poemDataFrame <- cbind(poemName, poemDataFrame)\n  \n  # get scores\n  \n  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)\n  \n  dateAndScore <- data.frame(scores) %>%\n    mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\")))) \n\n  # do nrs analysis\n  \n  sentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                     \"joy\",\"sadness\", \"surprise\", \"trust\")\n  \n  nrsAnalysisDataFrame <- list()\n  \n  for (i in 1:length(poemDataFrame$poem)) {\n    \n    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n      rownames_to_column() %>%\n      select(sentiment = rowname, value = 2) %>%\n      mutate(name = poemDataFrame$poemName[i], \n             date = poemDataFrame$date[i])\n    \n    nrsAnalysisDataFrame[[i]] <- nrsDataFrame\n  }\n  \n  # rbind all nrs analysis\n  \n  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)\n  \n  # return data frames \n  \n  return(list(dateAndScore, nrsAnalysisDataFrame))\n}\n\n## Scrape for Frost ##\n\nFrost <- function() {\n  \n  # function to scrape for poem and it's date using poem names\n  \n  GetPoemAndDate <- function(poemName) {\n    \n    nameVec <- unlist(str_split(poemName, pattern = \" \"))\n    \n    url <- str_c(\"http://www.poetry-archive.com/f/\", \n                 paste(nameVec, collapse = \"_\"),\n                 \".html\") \n    \n    poem <- url %>%\n      read_html() %>%\n      html_nodes(\"dl\") %>%\n      html_text() %>%\n      str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n      str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n      str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n    \n    date <- url %>%\n      read_html() %>%\n      html_nodes(\"td font\") %>%\n      html_text() \n    \n    date <- date[4] %>%\n      str_extract(pattern = \"[0-9]+\")\n    \n    # pause before function return\n    \n    Sys.sleep(runif(1,0,1))\n    \n    return(list(poem = poem, date = date))\n  }\n  \n  # function to analyse poems and return scores\n  \n  AnalysePoems <- function(i) {\n    \n    poem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    textTokenized <- poem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    bing <- sentiments %>%\n      filter(lexicon == \"bing\") %>%\n      select(-score)\n    \n    poemSentiment <- tidyPoem %>%\n      inner_join(bing) \n    \n    poemSentiment <- poemSentiment %>%\n      mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n    \n    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n    \n    return(finalScore)\n  }\n  \n  # nrs analysis function \n  \n  nrcAnalysePoems <- function(sent) {\n    \n    textTokenized <- nrsPoem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    nrcSentiment <- sentiments %>%\n      filter(lexicon == \"nrc\", sentiment == sent)\n    \n    sentimentInPoem <- tidyPoem %>%\n      semi_join(nrcSentiment) %>%\n      count(word, sort = TRUE)\n    \n    return(sum(sentimentInPoem$n))\n  }\n  \n  # page url\n  \n  poemNameUrl <- \"http://www.poetry-archive.com/f/frost_robert.html\"\n  \n  # scrape for poem names\n  \n  poemName <- poemNameUrl %>%\n    read_html() %>%\n    html_nodes(\"a font\") %>%\n    html_text() \n  \n  poemName <- poemName[1:(length(poemName) - 2)] %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n    str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n    tolower()\n  \n  # hardcode poem name to fit in with used url name\n  \n  poemName[10] <- \"the_oft-repeated_dream\"\n  poemName[14] <- \"range_finding\"\n  poemName[20] <- \"the_wood-pile\"\n  \n  # get poems and dates\n  \n  poemDataFrame <- list()\n  count <- 1\n  \n  for (name in poemName) {\n    \n    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, \n                                         date = GetPoemAndDate(name)$date,\n                                         stringsAsFactors = FALSE)\n    \n    count <- count + 1\n  }\n  \n  # rbind all poems and dates\n  \n  poemDataFrame <- do.call(rbind, poemDataFrame)\n  \n  # create data frame of names, poems and dates\n  \n  poemDataFrame <- cbind(poemName, poemDataFrame)\n  \n  # get scores\n  \n  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)\n  \n  dateAndScore <- data.frame(scores) %>%\n    mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\")))) \n\n  # do nrs analysis\n  \n  sentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                     \"joy\",\"sadness\", \"surprise\", \"trust\")\n  \n  nrsAnalysisDataFrame <- list()\n  \n  for (i in 1:length(poemDataFrame$poem)) {\n    \n    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n      rownames_to_column() %>%\n      select(sentiment = rowname, value = 2) %>%\n      mutate(name = poemDataFrame$poemName[i], \n             date = poemDataFrame$date[i])\n    \n    nrsAnalysisDataFrame[[i]] <- nrsDataFrame\n  }\n  \n  # rbind all nrs analysis\n  \n  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)\n  \n  # return data frames \n  \n  return(list(dateAndScore, nrsAnalysisDataFrame))\n}\n\n## Scrape for Wallace ##\n\nWallace <- function() {\n  \n  # function to scrape for poem and it's date using poem names\n  \n  GetPoemAndDate <- function(poemName) {\n    \n    nameVec <- unlist(str_split(poemName, pattern = \" \"))\n    \n    url <- str_c(\"http://www.poetry-archive.com/s/\", \n                 paste(nameVec, collapse = \"_\"),\n                 \".html\") \n    \n    poem <- url %>%\n      read_html() %>%\n      html_nodes(\"dl\") %>%\n      html_text() %>%\n      str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n      str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n      str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n    \n    date <- url %>%\n      read_html() %>%\n      html_nodes(\"td font\") %>%\n      html_text() \n    \n    date <- date[3] %>%\n      str_extract(pattern = \"[0-9]+\")\n    \n    # pause before function return\n    \n    Sys.sleep(runif(1,0,1))\n    \n    return(list(poem = poem, date = date))\n  }\n  \n  # function to analyse poems and return scores\n  \n  AnalysePoems <- function(i) {\n    \n    poem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    textTokenized <- poem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    bing <- sentiments %>%\n      filter(lexicon == \"bing\") %>%\n      select(-score)\n    \n    poemSentiment <- tidyPoem %>%\n      inner_join(bing) \n    \n    poemSentiment <- poemSentiment %>%\n      mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n    \n    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n    \n    return(finalScore)\n  }\n  \n  # nrs analysis function \n  \n  nrcAnalysePoems <- function(sent) {\n    \n    textTokenized <- nrsPoem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    nrcSentiment <- sentiments %>%\n      filter(lexicon == \"nrc\", sentiment == sent)\n    \n    sentimentInPoem <- tidyPoem %>%\n      semi_join(nrcSentiment) %>%\n      count(word, sort = TRUE)\n    \n    return(sum(sentimentInPoem$n))\n  }\n  \n  # page url\n  \n  poemNameUrl <- \"http://www.poetry-archive.com/s/stevens_wallace.html\"\n  \n  # scrape for poem names\n  \n  poemName <- poemNameUrl %>%\n    read_html() %>%\n    html_nodes(\"a font\") %>%\n    html_text() \n  \n  poemName <- poemName[1:(length(poemName) - 2)] %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n    str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n    tolower()\n  \n  # hardcode poem name to fit in with used url name\n  \n  poemName[1] <- \"the_emperor_of_ice_cream\"\n  poemName[2] <- \"a_high_toned_old_christian_woman\"\n  # poemName[20] <- \"the_wood-pile\"\n  \n  # get poems and dates\n  \n  poemDataFrame <- list()\n  count <- 1\n  \n  for (name in poemName) {\n    \n    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, \n                                         date = GetPoemAndDate(name)$date,\n                                         stringsAsFactors = FALSE)\n    \n    count <- count + 1\n  }\n  \n  # rbind all poems and dates\n  \n  poemDataFrame <- do.call(rbind, poemDataFrame)\n  \n  poemDataFrame$date[3] <- \"1921\"\n  \n  # create data frame of names, poems and dates\n  \n  poemDataFrame <- cbind(poemName, poemDataFrame)\n  \n  # get scores\n  \n  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)\n  \n  dateAndScore <- data.frame(scores) %>%\n    mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\"))))\n  \n  # do nrs analysis\n  \n  sentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                     \"joy\",\"sadness\", \"surprise\", \"trust\")\n  \n  nrsAnalysisDataFrame <- list()\n  \n  for (i in 1:length(poemDataFrame$poem)) {\n    \n    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n      rownames_to_column() %>%\n      select(sentiment = rowname, value = 2) %>%\n      mutate(name = poemDataFrame$poemName[i], \n             date = poemDataFrame$date[i])\n    \n    nrsAnalysisDataFrame[[i]] <- nrsDataFrame\n  }\n  \n  # rbind all nrs analysis\n  \n  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)\n  \n  # return data frames \n  \n  return(list(dateAndScore, nrsAnalysisDataFrame))\n}\n\n## Scrape for Cummings ##\n\nCummings <- function() {\n  \n  # function to scrape for poem and it's date using poem names\n  \n  GetPoemAndDate <- function(poemName) {\n    \n    nameVec <- unlist(str_split(poemName, pattern = \" \"))\n    \n    url <- str_c(\"http://www.poetry-archive.com/c/\", \n                 paste(nameVec, collapse = \"_\"),\n                 \".html\") \n    \n    poem <- url %>%\n      read_html() %>%\n      html_nodes(\"dl\") %>%\n      html_text() %>%\n      str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n      str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n      str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n    \n    date <- url %>%\n      read_html() %>%\n      html_nodes(\"td font\") %>%\n      html_text() \n    \n    date <- date[4] %>%\n      str_extract(pattern = \"[0-9]{4}\")\n    \n    # pause before function return\n    \n    Sys.sleep(runif(1,0,1))\n    \n    return(list(poem = poem, date = date))\n  }\n  \n  # function to analyse poems and return scores\n  \n  AnalysePoems <- function(i) {\n    \n    poem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    textTokenized <- poem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    bing <- sentiments %>%\n      filter(lexicon == \"bing\") %>%\n      select(-score)\n    \n    poemSentiment <- tidyPoem %>%\n      inner_join(bing) \n    \n    poemSentiment <- poemSentiment %>%\n      mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n    \n    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n    \n    return(finalScore)\n  }\n  \n  # nrs analysis function \n  \n  nrcAnalysePoems <- function(sent) {\n    \n    textTokenized <- nrsPoem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    nrcSentiment <- sentiments %>%\n      filter(lexicon == \"nrc\", sentiment == sent)\n    \n    sentimentInPoem <- tidyPoem %>%\n      semi_join(nrcSentiment) %>%\n      count(word, sort = TRUE)\n    \n    return(sum(sentimentInPoem$n))\n  }\n  \n  # page url\n  \n  poemNameUrl <- \"http://www.poetry-archive.com/c/cummings_e_e.html\"\n  \n  # scrape for poem names\n  \n  poemName <- poemNameUrl %>%\n    read_html() %>%\n    html_nodes(\"a font\") %>%\n    html_text() \n  \n  poemName <- poemName[1:(length(poemName) - 2)] %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n    str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n    tolower()\n  \n  # get poems and dates\n  \n  poemDataFrame <- list()\n  count <- 1\n  \n  for (name in poemName) {\n    \n    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, \n                                         date = GetPoemAndDate(name)$date,\n                                         stringsAsFactors = FALSE)\n    \n    count <- count + 1\n  }\n  \n  # rbind all poems and dates\n  \n  poemDataFrame <- do.call(rbind, poemDataFrame)\n  \n  # create data frame of names, poems and dates\n  \n  poemDataFrame <- cbind(poemName, poemDataFrame)\n  \n  # get scores\n  \n  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)\n  \n  dateAndScore <- data.frame(scores) %>%\n    mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\")))) \n\n  # do nrs analysis\n  \n  sentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                     \"joy\",\"sadness\", \"surprise\", \"trust\")\n  \n  nrsAnalysisDataFrame <- data.frame()\n  \n  for (i in 1:length(poemDataFrame$poem)) {\n    \n    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])\n\n    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n      rownames_to_column() %>%\n      select(sentiment = rowname, value = 2) %>%\n      mutate(name = poemDataFrame$poemName[i], \n             date = poemDataFrame$date[i])\n    \n    nrsAnalysisDataFrame <- rbind(nrsAnalysisDataFrame, nrsDataFrame)\n  }\n  \n  # return data frames \n  \n  return(list(dateAndScore, nrsAnalysisDataFrame))\n}\n\n## Scrape for Lawrence ##\n\nLawrence <- function() {\n  \n  # function to scrape for poem and it's date using poem names\n  \n  GetPoemAndDate <- function(poemName) {\n    \n    nameVec <- unlist(str_split(poemName, pattern = \" \"))\n    \n    url <- str_c(\"http://www.poetry-archive.com/l/\", \n                 paste(nameVec, collapse = \"_\"),\n                 \".html\") \n    \n    poem <- url %>%\n      read_html() %>%\n      html_nodes(\"dl\") %>%\n      html_text() %>%\n      str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n      str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n      str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n    \n    date <- url %>%\n      read_html() %>%\n      html_nodes(\"td font\") %>%\n      html_text() \n    \n    date <- date[4] %>%\n      str_extract(pattern = \"[0-9]{4}\")\n    \n    # pause before function return\n    \n    Sys.sleep(runif(1,0,1))\n    \n    return(list(poem = poem, date = date))\n  }\n  \n  # function to analyse poems and return scores\n  \n  AnalysePoems <- function(i) {\n    \n    poem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    textTokenized <- poem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    bing <- sentiments %>%\n      filter(lexicon == \"bing\") %>%\n      select(-score)\n    \n    poemSentiment <- tidyPoem %>%\n      inner_join(bing) \n    \n    poemSentiment <- poemSentiment %>%\n      mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n    \n    finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n    \n    return(finalScore)\n  }\n  \n  # nrs analysis function \n  \n  nrcAnalysePoems <- function(sent) {\n    \n    textTokenized <- nrsPoem %>%\n      unnest_tokens(word, poem)\n    \n    data(\"stop_words\")\n    \n    tidyPoem <- textTokenized %>%\n      anti_join(stop_words)\n    \n    nrcSentiment <- sentiments %>%\n      filter(lexicon == \"nrc\", sentiment == sent)\n    \n    sentimentInPoem <- tidyPoem %>%\n      semi_join(nrcSentiment) %>%\n      count(word, sort = TRUE)\n    \n    return(sum(sentimentInPoem$n))\n  }\n  \n  # page url\n  \n  poemNameUrl <- \"http://www.poetry-archive.com/l/lawrence_d_h.html\"\n  \n  # scrape for poem names\n  \n  poemName <- poemNameUrl %>%\n    read_html() %>%\n    html_nodes(\"a font\") %>%\n    html_text() \n  \n  poemName <- poemName[1:(length(poemName) - 2)] %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n    str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n    tolower()\n  \n  # get poems and dates\n  \n  poemDataFrame <- list()\n  count <- 1\n  \n  for (name in poemName) {\n    \n    poemDataFrame[[count]] <- data.frame(poem = GetPoemAndDate(name)$poem, \n                                         date = GetPoemAndDate(name)$date,\n                                         stringsAsFactors = FALSE)\n    \n    count <- count + 1\n  }\n  \n  # rbind all poems and dates\n  \n  poemDataFrame <- do.call(rbind, poemDataFrame)\n  \n  # hardcode single date with error \n  \n  poemDataFrame$date[3] <- 1916\n  \n  # create data frame of names, poems and dates\n  \n  poemDataFrame <- cbind(poemName, poemDataFrame)\n  \n  # get scores\n  \n  scores <- sapply(1:length(poemDataFrame$poem), AnalysePoems)\n  \n  dateAndScore <- data.frame(scores) %>%\n    mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\")))) \n\n  # do nrs analysis\n  \n  sentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                     \"joy\",\"sadness\", \"surprise\", \"trust\")\n  \n  nrsAnalysisDataFrame <- list()\n  \n  for (i in 1:length(poemDataFrame$poem)) {\n    \n    nrsPoem <- data_frame(poem = poemDataFrame$poem[i])\n    \n    nrsDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n      rownames_to_column() %>%\n      select(sentiment = rowname, value = 2) %>%\n      mutate(name = poemDataFrame$poemName[i], \n             date = poemDataFrame$date[i])\n    \n    nrsAnalysisDataFrame[[i]] <- nrsDataFrame\n  }\n  \n  # rbind all nrs analysis\n  \n  nrsAnalysisDataFrame <- do.call(rbind, nrsAnalysisDataFrame)\n  \n  # return data frames \n  \n  return(list(dateAndScore, nrsAnalysisDataFrame))\n}\n\nmultiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {\n  library(grid)\n\n  # Make a list from the ... arguments and plotlist\n  plots <- c(list(...), plotlist)\n\n  numPlots = length(plots)\n\n  # If layout is NULL, then use 'cols' to determine layout\n  if (is.null(layout)) {\n    # Make the panel\n    # ncol: Number of columns of plots\n    # nrow: Number of rows needed, calculated from # of cols\n    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),\n                    ncol = cols, nrow = ceiling(numPlots/cols))\n  }\n\n if (numPlots==1) {\n    print(plots[[1]])\n\n  } else {\n    # Set up the page\n    grid.newpage()\n    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))\n\n    # Make each plot, in the correct location\n    for (i in 1:numPlots) {\n      # Get the i,j matrix positions of the regions that contain this subplot\n      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))\n\n      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,\n                                      layout.pos.col = matchidx$col))\n    }\n  }\n}\n\n```\n\nThe website used for scraping has a page to list each poem available for each poet, then a seperate page for each of the poems in the list, along with their dates; therefore an initial scrape using `rvest` is done to get the names. The names are then cleaned and used in the urls to get the poems and dates. Some names were not exactly the same as their url versions, so they needed to be manually changed. \n\n```{r scrape_poem_names}\n\n# page url\npoemNameUrl <- \"http://www.poetry-archive.com/y/yeats_w_b.html\"\n\n# scrape for poem names\npoemName <- poemNameUrl %>%\n  read_html() %>%\n  html_nodes(\"a font\") %>%\n  html_text() \n\n# clean \npoemName <- poemName[1:50] %>%\n  str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n  str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n  str_replace_all(pattern = \"[  ]{2}\", replacement = \"\") %>%\n  str_replace_all(pattern = \"[[:punct:]]\", replacement = \"\") %>%\n  tolower()\n\n# hardcode 2 poem names to fit in with used url name\npoemName[9] <- \"he mourns for the change\"\npoemName[24] <- \"the old men admiring themselves\"\n\n# display\nhead(poemName, 10)\n  \n```\n\nNext I use a function that takes a poem name -- and again using `rvest` -- scrapes for the given poem and its date, then cleans the text and waits before returning. \n\n```{r get_poem_and_date_function}\n\n# function to scrape for poem and its date using poem names \nGetPoemAndDate <- function(poemName) {\n    \n  nameVec <- unlist(str_split(poemName, pattern = \" \"))\n  \n  url <- str_c(\"http://www.poetry-archive.com/y/\", \n               paste(nameVec, collapse = \"_\"),\n               \".html\") \n  \n  # scrape for poem and clean\n  poem <- url %>%\n    read_html() %>%\n    html_nodes(\"dl\") %>%\n    html_text() %>%\n    str_replace_all(pattern = \"\\r\", replacement = \"\") %>%\n    str_replace_all(pattern = \"\\n\", replacement = \" \") %>%\n    str_replace_all(pattern = \"[  ]{2}\", replacement = \"\")\n  \n  # scrape for date \n  date <- url %>%\n    read_html() %>%\n    html_nodes(\"td font\") %>%\n    html_text() \n  \n  # clean dates\n  date <- date[3] %>%\n    str_extract(pattern = \"[0-9]+\")\n \n  # pause before function return\n  Sys.sleep(runif(1,0,1))\n  \n  return(list(poem = poem, date = date))\n}\n\n```\n\nI then use this function in a for loop which loops through each name, scrapes, adds the data frame of poems and dates to a list and finally once the loop has completed `rbind`s all the data frames together.  \n\n```{r get_poem_and_date}\n\n# get poems and dates\npoemDataFrame <- list()\ncount <- 1\n\nfor (name in poemName) {\n  \n  # get poem and date for given poem name\n  poemNameDate <- GetPoemAndDate(name)\n  \n  # create data frame of name and date and add it to list\n  poemDataFrame[[count]] <- data.frame(poem = poemNameDate$poem, \n                                       date = poemNameDate$date,\n                           stringsAsFactors = FALSE)\n  \n  count <- count + 1\n}\n\n# rbind all poems and dates\npoemDataFrame <- do.call(rbind, poemDataFrame)\n\n```\n\nI then combine the names, dates and poems into a single data frame ready for analysis. I also check for errors and correct any found. In this case a date.\n\n```{r combine_names_dates_poems}\n\n# create data frame of names, poems and dates\npoemDataFrame <- cbind(poemName, poemDataFrame)\n\n# hardcode single date with error\npoemDataFrame$date[40] <- \"1916\"\n\n```\n\nThe next function I have written takes a row index and using `tidytext`, tokenizes the poem in the poem data frame into single words, it then uses `anti_join` from `dplyr`, along with the `stop_words` dataset from `tidytext`, to create a tibble of these words. This new tibble, now without a list of stop words which will not be helpful in the analysis. Finally, using `inner_join` and the `sentiment` dataset filtered on the bing lexicon, again from `tidytext`, it calculates a score value for the poem depending on the number of negative and positive words, and returns this as a percentage of the number of words in that particular poem. \n\n```{r bing_analysis_function}\n\n# function to analyse poems and return scores using bing lexicon\nbingAnalysePoems <- function(i) {\n  \n  poem <- data_frame(poem = poemDataFrame$poem[i])\n  \n  # tokenize into words\n  textTokenized <- poem %>%\n    unnest_tokens(word, poem)\n  \n  data(\"stop_words\")\n  \n  # anti join on stop words\n  tidyPoem <- textTokenized %>%\n    anti_join(stop_words)\n  \n  # filter on bing lexicon\n  bing <- sentiments %>%\n    filter(lexicon == \"bing\") %>%\n    select(-score)\n  \n  # join on bing to get whether words are positive or negative\n  poemSentiment <- tidyPoem %>%\n    inner_join(bing) \n  \n  # get score for poem\n  poemSentiment <- poemSentiment %>%\n    mutate(score = ifelse(poemSentiment$sentiment == \"positive\", 1, -1))\n  \n  # get score as a percentage of total words in poem\n  finalScore <- (sum(poemSentiment$score)/length(textTokenized$word))*10\n  \n  return(finalScore)\n}\n\n```\n\nNow, using the previous function and `sapply` I get the score for each poem and create a data frame with that score and the year.  \n\n```{r get_scores, message = FALSE}\n\n# get scores\nscores <- sapply(1:length(poemDataFrame$poem), bingAnalysePoems)\n\n# create data frame with data and scores\ndateAndScore <- data.frame(scores) %>%\n  mutate(date = year(ymd(str_c(poemDataFrame$date, \"/01/01\"))))\n  \n# display\nhead(dateAndScore, 10)\n\n```\n\nThe next function I have written takes a particular sentiment from a number of sentiments found in the NRC lexicon of the `sentiment` dataset, it then again creates a tibble of words not including stop words, and using `semi_join` and the `sentiment` dataset filtered on the NRC lexicon and the particular sentiment given, returns the sum of the number of words relating to that sentiment.\n\n```{r nrc_analysis_function}\n\n# NRC analysis function\nnrcAnalysePoems <- function(sent) {\n  \n  # nrcPoem used from global environment\n  textTokenized <- nrcPoem %>%\n    unnest_tokens(word, poem)\n  \n  data(\"stop_words\")\n  \n  tidyPoem <- textTokenized %>%\n    anti_join(stop_words)\n  \n  # filter on NRC lexicon and sentiment\n  nrcSentiment <- sentiments %>%\n    filter(lexicon == \"nrc\", sentiment == sent)\n  \n  # join on sentiment and count words\n  sentimentInPoem <- tidyPoem %>%\n    semi_join(nrcSentiment) %>%\n    count(word, sort = TRUE)\n  \n  # return the sum of the counted words\n  return(sum(sentimentInPoem$n))\n}\n\n```\n\nUsing the above function, `sapply` and a for loop, I then create a data frame consisting of each sentiment, the sum of words for that sentiment, the name of the poem and the date. I then add this data frame to a list.\n\n```{r nrc_analysis, message = FALSE}\n\n# list of used setiments found in NRC lexicon\nsentimentsVec <- c(\"anger\", \"anticipation\", \"disgust\", \"fear\",\n                   \"joy\",\"sadness\", \"surprise\", \"trust\")\n\nnrcAnalysisDataFrame <- list()\n\n# get a frequency percetage for each sentiment found in the NRC lexicon \nfor (i in 1:length(poemDataFrame$poem)) {\n  \n  # poem at index i - to be used in nrcAnalysePoems function environment\n  nrcPoem <- data_frame(poem = poemDataFrame$poem[i])\n  \n  # create data frame for each poem of all sentiment sums\n  nrcDataFrame <- as.data.frame(sapply(sentimentsVec, nrcAnalysePoems)) %>%\n    rownames_to_column() %>%\n    select(sentiment = rowname, value = 2) %>%\n    mutate(name = poemDataFrame$poemName[i], \n           date = poemDataFrame$date[i])\n  \n  nrcAnalysisDataFrame[[i]] <- nrcDataFrame\n}\n\n```\n\nOnce the for loop has completed I `rbind` all the data frames in the list.\n\n```{r rbind_NRC}\n\n\n# rbind list of all NRC sum values for all poems\nnrcAnalysisDataFrame <- do.call(rbind, nrcAnalysisDataFrame)\n\n# display\nhead(nrcAnalysisDataFrame, 10)\n\n```\n\nNow all the preparation code is done and we are ready for our analysis. For ease of use I have created a function for each poet to run all the code shown previously; the functions return both the bing and the NRC data frames. These functions are run but will not be shown here. \n\nFirstly I will need to call each poets function and assign the returned data frames to variables. \n\n```{r call_poet_functions, message = FALSE}\n\nyeats <- Yeats()\neliot <- Eliot()\nfrost <- Frost()\nwallace <- Wallace()\ncummings <- Cummings()\nlawrence <- Lawrence()\n\n```\n\nNext I will join all the bing scores for all the poets using `rbind`. I then group by date and get a mean score for each year in the data frame. This returns a tibble.\n\n```{r join_bing}\n\n# rbind data frames and summarize\ncompletedataFramebing <- rbind(yeats[[1]],\n                               eliot[[1]],\n                               frost[[1]],\n                             wallace[[1]],\n                            cummings[[1]],\n                            lawrence[[1]]) %>%\n  filter(date != \"1889\") %>%\n  group_by(date)  %>%\n  summarize(score = mean(scores))\n\n# display\nhead(completedataFramebing, 10)\n\n```\n\nNow it's time to plot the scores. \n\n```{r plot_bing, fig.height = 4, fig.width = 8}\n\n# plot bar plot\np1 <- ggplot(data = completedataFramebing) +\n  geom_bar(aes(x = date, y = score, fill = score), \n           stat = \"identity\", position = \"identity\") +\n  ylim(-1, 1) +\n  ylab(\"mean percentage score\") +\n  xlab(\"year\") +\n  theme(legend.key.size = unit(0.5, \"cm\"),\n        legend.text = element_text(size = 7),\n        legend.position = c(0.87, 0.77))\n\n# plot dot and line plot\np2 <- ggplot(data = completedataFramebing) +\n  geom_line(aes(x = date, y = score), colour = \"blue\") +\n  geom_point(aes(x = date, y = score), size = 1.3, colour = \"blue\") +\n  ylim(-1, 1) +\n  ylab(\"mean percentage score\") +\n  xlab(\"year\")\n\n# use multiplot function \n# can be found at http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/\nmultiplot(p1, p2, cols = 2)\n\n```\n\nThe 0 values in the bar plot are not all actual 0 values but rather years where no information is available. The plots show a steady decline between the period 1890 - 1900, then due to a lack of data very little can be seen during the period from 1900 - 1915, after which there is again a massive decline between 1915 and 1920 and again a small drop between 1920 and 1925.\n\nFinally let's look at the NRC analysis. Firstly, I join each poet's NRC data frame using `rbind`, then group them by date and sentiment, sum the sentiment values for each poem and use this sum to get percentage values for each sentiment for each year.  \n\n```{r join_NRC}\n\n\nyeatsnrc <- rbind(yeats[[2]],\n                  eliot[[2]],\n                  frost[[2]],\n                wallace[[2]],\n               cummings[[2]],\n               lawrence[[2]]) %>%\n  filter(date != \"1889\") %>%\n  group_by(date, sentiment) %>%\n  summarise(dateSum = sum(value)) %>%\n  mutate(dateFreqPerc = dateSum/sum(dateSum))\n\n\nhead(yeatsnrc, 10)\n\n```\n\nNow I plot the sentiment percentage values for each year.\n\n```{r plot_NRC, fig.height = 8, fig.width = 6}\n\nggplot(data = yeatsnrc, aes(x = sentiment, \n                            y = dateFreqPerc, \n                         fill = sentiment)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Spectral\") +\n  guides(fill = FALSE) +\n  facet_wrap(~date, ncol = 2) +\n  theme(axis.text.x = element_text(\n              angle = 45, \n              hjust = 1,\n               size = 8)) +\n theme(axis.title.y = element_text(margin = margin(0, 10, 0, 0))) +\n  ylab(\"frequency percentage\")\n\n```\n\nFrom these plots we can see how sentiment changes through the years of available data. During the early 1890s we see equal percentages of anticipation, fear, joy, sadness and trust, while later we see anticipation, joy and trust. In 1903 joy takes the lead, but in 1910 and 1915 we see anticipation and trust increasing with fear and joy equal. In 1916 fear and sadness are high and 1917 anger, fear, sadness and trust are notibly high. From 1918 - 1919 we see a change from negative to positive with Joy taking a big lead in 1919 and again in 1920. 1921 sees sadness again with others coming in with mostly equal parts, and 1922 anticipation, joy and trust. \n\nI am not a historian but fortunately my sister majored in history, so I asked her to send me a timeline of influencial world events between the years this analysis is based on. I have used this timeline to explain my findings. \n\nFrom both the bing and NRC analysis it can be seen that there was a very apparent negative trend during the years from 1915 - 1920, this is very possibly due to a number of world events, namely; World War I during the years from 1914 - 1918, the influenza pandemic which lasted from 1918 - 1919, and the Russian Revolution in 1917. Another negative trend seems to appear at the end of the 19th Century, this time it is possibly due to the Boer War, which lasted from 1899 - 1902 and had repurcussions across Europe, as well as the India epidemic which killed around 1 million people during the years 1899 and 1900. \n\nA few things to be mentioned:  \n\n<ol>\n<li> A word from a colleague who majored in english literature; as we all know the pop artists of the time will always move with popular trends, so it could be that the poets chosen, being the most popular during the years this analysis is based on, may have been more likely to be influenced by the events around them </li>\n<li> Due to the surprisingly difficult task of finding poetry with enough information, this analysis has been based on only a small number of poems </li>\n</ol>\n\n\nThis being said, it still seems very likely that poets as a whole are influenced by the world events of their time. \n\n\n\n",
    "created" : 1477481158356.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "798558707",
    "id" : "AD631BEB",
    "lastKnownWriteTime" : 1477484164,
    "last_content_update" : 1477484164045,
    "path" : "~/t-drive/Internal/Stats_team/Blog_work_folder/Sentiment_Analysis_Poetry/sentiment_blog_post.Rmd",
    "project_path" : "sentiment_blog_post.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}